name: vllm-test

on:
  push:
    tags:
      - ciflow/vllm/*
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}
  cancel-in-progress: true

permissions:
  id-token: write
  contents: read

jobs:
  get-label-type:
    name: get-label-type
    uses: pytorch/pytorch/.github/workflows/_runner-determinator.yml@main
    if: ${{ (github.event_name != 'schedule' || github.repository == 'pytorch/pytorch') && github.repository_owner == 'pytorch' }}
    with:
      triggering_actor: ${{ github.triggering_actor }}
      issue_owner: ${{ github.event.pull_request.user.login || github.event.issue.user.login }}
      curr_branch: ${{ github.head_ref || github.ref_name }}
      curr_ref_type: ${{ github.ref_type }}
      opt_out_experiments: lf

  torch-build-sm89:
    name: ci-vllm-test-sm89
    uses: ./.github/workflows/_linux-build.yml
    needs: get-label-type
    with:
      build-additional-packages: "vision audio"
      build-external-packages: "vllm"
      build-environment: linux-jammy-cuda12.8-py3.12-gcc11-sm89
      docker-image-name: ci-image:pytorch-linux-jammy-cuda12.8-cudnn9-py3.12-gcc11-vllm
      cuda-arch-list: '8.0 8.9'
      runner: linux.24xlarge.memory
      test-matrix: |
        { include: [
          { config: "vllm_basic_correctness_test", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g6.4xlarge.experimental.nvidia.gpu"  },
          { config: "vllm_basic_models_test", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g6.4xlarge.experimental.nvidia.gpu" },
          { config: "vllm_regression_test", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g6.4xlarge.experimental.nvidia.gpu" },
          { config: "vllm_entrypoints_test", shard: 1, num_shards: 1,runner: "${{ needs.get-label-type.outputs.label-type }}linux.g6.4xlarge.experimental.nvidia.gpu" },
        ]}
    secrets: inherit

  vllm-test-sm89:
      name: ci-vllm-test-sm89
      uses: ./.github/workflows/_linux-test.yml
      needs: [
        torch-build-sm89,
      ]
      with:
        build-environment: linux-jammy-cuda12.8-py3.12-gcc11-sm89
        docker-image: ${{ needs.torch-build-sm89.outputs.docker-image }}
        test-matrix: ${{ needs.torch-build-sm89.outputs.test-matrix }}
      secrets: inherit

  torch-build-sm80:
    name: ci-vllm-test-sm80
    uses: ./.github/workflows/_linux-build.yml
    needs: get-label-type
    with:
      build-additional-packages: "vision audio"
      build-external-packages: "vllm"
      build-environment: linux-jammy-cuda12.8-py3.12-gcc11-sm80
      docker-image-name: ci-image:pytorch-linux-jammy-cuda12.8-cudnn9-py3.12-gcc11-vllm
      cuda-arch-list: '8.0'
      runner: linux.24xlarge.memory
      test-matrix: |
        { include: [
          { config: "vllm_basic_correctness_test", shard: 1, num_shards: 1, runner: "linux.aws.a100" },
          { config: "vllm_basic_models_test", shard: 1, num_shards: 1, runner: "linux.aws.a100" },
          { config: "vllm_regression_test", shard: 1, num_shards: 1, runner: "linux.aws.a100" },
          { config: "vllm_entrypoints_test", shard: 1, num_shards: 1, runner: "linux.aws.a100" },
        ]}
    secrets: inherit

  vllm-test-sm80:
    name: ci-vllm-test-sm80
    uses: ./.github/workflows/_linux-test.yml
    needs: [
      torch-build-sm80,
    ]
    with:
      build-environment: linux-jammy-cuda12.8-py3.12-gcc11-sm80
      docker-image: ${{ needs.torch-build-sm80.outputs.docker-image }}
      test-matrix: ${{ needs.torch-build-sm80.outputs.test-matrix }}
    secrets: inherit
